{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598b7482",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "996c553b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>Black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>I swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>Yea fuck you RT @therealexel: IF YOURE A NIGGE...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type\n",
       "0      In other words #katandandre, your food was cra...  not_cyberbullying\n",
       "1      Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
       "2      @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
       "3      @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
       "4      @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying\n",
       "...                                                  ...                ...\n",
       "47687  Black ppl aren't expected to do anything, depe...          ethnicity\n",
       "47688  Turner did not withhold his disappointment. Tu...          ethnicity\n",
       "47689  I swear to God. This dumb nigger bitch. I have...          ethnicity\n",
       "47690  Yea fuck you RT @therealexel: IF YOURE A NIGGE...          ethnicity\n",
       "47691  Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...          ethnicity\n",
       "\n",
       "[47692 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/christianholm/Desktop/cyberbullying_tweets.csv')\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a15a8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a first round of text cleaning techniques\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)\n",
    "\n",
    "# Apply a second round of cleaning\n",
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‚Äò‚Äô‚Äú‚Äù‚Ä¶]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f80825b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.DataFrame(df.tweet_text.apply(round1))\n",
    "df['tweet_text'] = clean_data['tweet_text']\n",
    "\n",
    "clean_data = pd.DataFrame(df.tweet_text.apply(round2))\n",
    "df['tweet_text'] = clean_data['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbc0cf43",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words katandandre your food was crapi...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is aussietv so white mkr theblock imaceleb...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xochitlsuckkks a classy whore or more red velv...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jasongio meh p  thanks for the heads up but no...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rudhoeenglish this is an isis account pretendi...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>black ppl arent expected to do anything depend...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>turner did not withhold his disappointment tur...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>i swear to god this dumb nigger bitch i have g...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>yea fuck you rt therealexel if youre a nigger ...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>bro u gotta chill rt chillshrammy dog fuck kp ...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type\n",
       "0      in other words katandandre your food was crapi...  not_cyberbullying\n",
       "1      why is aussietv so white mkr theblock imaceleb...  not_cyberbullying\n",
       "2      xochitlsuckkks a classy whore or more red velv...  not_cyberbullying\n",
       "3      jasongio meh p  thanks for the heads up but no...  not_cyberbullying\n",
       "4      rudhoeenglish this is an isis account pretendi...  not_cyberbullying\n",
       "...                                                  ...                ...\n",
       "47687  black ppl arent expected to do anything depend...          ethnicity\n",
       "47688  turner did not withhold his disappointment tur...          ethnicity\n",
       "47689  i swear to god this dumb nigger bitch i have g...          ethnicity\n",
       "47690  yea fuck you rt therealexel if youre a nigger ...          ethnicity\n",
       "47691  bro u gotta chill rt chillshrammy dog fuck kp ...          ethnicity\n",
       "\n",
       "[47692 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfe00ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "df.to_pickle('datapickle.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c41f338",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianholm/Desktop/SoftwareDevelopment/AAI/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aaaaaaaaaa</th>\n",
       "      <th>aaaaaaaaaaaaaaaaaaaaaah</th>\n",
       "      <th>aaaaaaaaaah</th>\n",
       "      <th>aaaaaaaaaajajajajajajajahahahajahaja</th>\n",
       "      <th>aaaaaaaahhhhhhh</th>\n",
       "      <th>aaaaah</th>\n",
       "      <th>...</th>\n",
       "      <th>ùïôùïíùï£ùï£ùïöùï§ùï†ùïü</th>\n",
       "      <th>ùï†ùïò</th>\n",
       "      <th>ùï¢ùï¶ùïñùï§ùï•ùïöùï†ùïü</th>\n",
       "      <th>ùï£ùï†ùïüùïüùïöùïñ</th>\n",
       "      <th>ùï§ùï†ùï¶ùï£ùïîùïñ</th>\n",
       "      <th>ùï•ùïôùïñ</th>\n",
       "      <th>ùïßùïñùï£ùï†ùïüùïöùïîùïí</th>\n",
       "      <th>ùï®ùï†ùï¶ùïùùïï</th>\n",
       "      <th>ùï´ùï†ùïñùï™</th>\n",
       "      <th>ùöéùöïùöûùöúùöíùöüùöé</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows √ó 58267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aaaa  aaaaa  aaaaaaaaaa  aaaaaaaaaaaaaaaaaaaaaah  aaaaaaaaaah  \\\n",
       "0       0    0     0      0           0                        0            0   \n",
       "1       0    0     0      0           0                        0            0   \n",
       "2       0    0     0      0           0                        0            0   \n",
       "3       0    0     0      0           0                        0            0   \n",
       "4       0    0     0      0           0                        0            0   \n",
       "...    ..  ...   ...    ...         ...                      ...          ...   \n",
       "47687   0    0     0      0           0                        0            0   \n",
       "47688   0    0     0      0           0                        0            0   \n",
       "47689   0    0     0      0           0                        0            0   \n",
       "47690   0    0     0      0           0                        0            0   \n",
       "47691   0    0     0      0           0                        0            0   \n",
       "\n",
       "       aaaaaaaaaajajajajajajajahahahajahaja  aaaaaaaahhhhhhh  aaaaah  ...  \\\n",
       "0                                         0                0       0  ...   \n",
       "1                                         0                0       0  ...   \n",
       "2                                         0                0       0  ...   \n",
       "3                                         0                0       0  ...   \n",
       "4                                         0                0       0  ...   \n",
       "...                                     ...              ...     ...  ...   \n",
       "47687                                     0                0       0  ...   \n",
       "47688                                     0                0       0  ...   \n",
       "47689                                     0                0       0  ...   \n",
       "47690                                     0                0       0  ...   \n",
       "47691                                     0                0       0  ...   \n",
       "\n",
       "       ùïôùïíùï£ùï£ùïöùï§ùï†ùïü  ùï†ùïò  ùï¢ùï¶ùïñùï§ùï•ùïöùï†ùïü  ùï£ùï†ùïüùïüùïöùïñ  ùï§ùï†ùï¶ùï£ùïîùïñ  ùï•ùïôùïñ  ùïßùïñùï£ùï†ùïüùïöùïîùïí  ùï®ùï†ùï¶ùïùùïï  ùï´ùï†ùïñùï™  \\\n",
       "0             0   0         0       0       0    0         0      0     0   \n",
       "1             0   0         0       0       0    0         0      0     0   \n",
       "2             0   0         0       0       0    0         0      0     0   \n",
       "3             0   0         0       0       0    0         0      0     0   \n",
       "4             0   0         0       0       0    0         0      0     0   \n",
       "...         ...  ..       ...     ...     ...  ...       ...    ...   ...   \n",
       "47687         0   0         0       0       0    0         0      0     0   \n",
       "47688         0   0         0       0       0    0         0      0     0   \n",
       "47689         0   0         0       0       0    0         0      0     0   \n",
       "47690         0   0         0       0       0    0         0      0     0   \n",
       "47691         0   0         0       0       0    0         0      0     0   \n",
       "\n",
       "       ùöéùöïùöûùöúùöíùöüùöé  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "47687        0  \n",
       "47688        0  \n",
       "47689        0  \n",
       "47690        0  \n",
       "47691        0  \n",
       "\n",
       "[47692 rows x 58267 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(df.tweet_text)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = df.index\n",
    "data_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117b1ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dtm.to_pickle(\"dtm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3e4a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cv, open(\"cv.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2215efb7",
   "metadata": {},
   "source": [
    "# Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91018d0c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47682</th>\n",
       "      <th>47683</th>\n",
       "      <th>47684</th>\n",
       "      <th>47685</th>\n",
       "      <th>47686</th>\n",
       "      <th>47687</th>\n",
       "      <th>47688</th>\n",
       "      <th>47689</th>\n",
       "      <th>47690</th>\n",
       "      <th>47691</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaaaaaa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 47692 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7      8      \\\n",
       "aa              0      0      0      0      0      0      0      0      0   \n",
       "aaa             0      0      0      0      0      0      0      0      0   \n",
       "aaaa            0      0      0      0      0      0      0      0      0   \n",
       "aaaaa           0      0      0      0      0      0      0      0      0   \n",
       "aaaaaaaaaa      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "            9      ...  47682  47683  47684  47685  47686  47687  47688  \\\n",
       "aa              0  ...      0      0      0      0      0      0      0   \n",
       "aaa             0  ...      0      0      0      0      0      0      0   \n",
       "aaaa            0  ...      0      0      0      0      0      0      0   \n",
       "aaaaa           0  ...      0      0      0      0      0      0      0   \n",
       "aaaaaaaaaa      0  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "            47689  47690  47691  \n",
       "aa              0      0      0  \n",
       "aaa             0      0      0  \n",
       "aaaa            0      0      0  \n",
       "aaaaa           0      0      0  \n",
       "aaaaaaaaaa      0      0      0  \n",
       "\n",
       "[5 rows x 47692 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('dtm.pkl')\n",
    "data = data.transpose()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1b79aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset1 = df[df['cyberbullying_type']=='gender']\n",
    "text_gender = subset1.tweet_text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d1a353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    \"\"\"\n",
    "    List the top n words in a vocabulary according to occurrence in a text corpus.\n",
    "    \"\"\"\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "477b44f6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words katandandre your food was crapi...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is aussietv so white mkr theblock imaceleb...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xochitlsuckkks a classy whore or more red velv...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jasongio meh p  thanks for the heads up but no...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rudhoeenglish this is an isis account pretendi...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>black ppl arent expected to do anything depend...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>turner did not withhold his disappointment tur...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>i swear to god this dumb nigger bitch i have g...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>yea fuck you rt therealexel if youre a nigger ...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>bro u gotta chill rt chillshrammy dog fuck kp ...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type\n",
       "0      in other words katandandre your food was crapi...  not_cyberbullying\n",
       "1      why is aussietv so white mkr theblock imaceleb...  not_cyberbullying\n",
       "2      xochitlsuckkks a classy whore or more red velv...  not_cyberbullying\n",
       "3      jasongio meh p  thanks for the heads up but no...  not_cyberbullying\n",
       "4      rudhoeenglish this is an isis account pretendi...  not_cyberbullying\n",
       "...                                                  ...                ...\n",
       "47687  black ppl arent expected to do anything depend...          ethnicity\n",
       "47688  turner did not withhold his disappointment tur...          ethnicity\n",
       "47689  i swear to god this dumb nigger bitch i have g...          ethnicity\n",
       "47690  yea fuck you rt therealexel if youre a nigger ...          ethnicity\n",
       "47691  bro u gotta chill rt chillshrammy dog fuck kp ...          ethnicity\n",
       "\n",
       "[47692 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8707b01c",
   "metadata": {},
   "source": [
    "# Michaels Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dd250216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/christianholm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/christianholm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/christianholm/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/christianholm/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/christianholm/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/christianholm/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1c3ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_english_stopwords_func(text):\n",
    "    '''\n",
    "    Removes Stop Words (also capitalized) from a string, if present\n",
    "    \n",
    "    Args:\n",
    "        text (str): String to which the function is to be applied, string\n",
    "    \n",
    "    Returns:\n",
    "        Clean string without Stop Words\n",
    "    ''' \n",
    "    # check in lowercase \n",
    "    t = [token for token in text if token.lower() not in stopwords.words(\"english\")]\n",
    "    text = ' '.join(t)    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7076af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_func(text):\n",
    "    '''\n",
    "    Counts words within a string\n",
    "    \n",
    "    Args:\n",
    "        text (str): String to which the function is to be applied, string\n",
    "    \n",
    "    Returns:\n",
    "        Number of words within a string, integer\n",
    "    ''' \n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a1fd82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_text_tokenized'] = df['tweet_text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34d2bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Token_Count'] = df['tweet_text_tokenized'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42871188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Word_Count'] = df['tweet_text'].apply(word_count_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94a612c2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>tweet_text_tokenized</th>\n",
       "      <th>Token_Count</th>\n",
       "      <th>Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words katandandre your food was crapi...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[in, other, words, katandandre, your, food, wa...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is aussietv so white mkr theblock imaceleb...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[why, is, aussietv, so, white, mkr, theblock, ...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xochitlsuckkks a classy whore or more red velv...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[xochitlsuckkks, a, classy, whore, or, more, r...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jasongio meh p  thanks for the heads up but no...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[jasongio, meh, p, thanks, for, the, heads, up...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rudhoeenglish this is an isis account pretendi...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[rudhoeenglish, this, is, an, isis, account, p...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>black ppl arent expected to do anything depend...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[black, ppl, arent, expected, to, do, anything...</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>turner did not withhold his disappointment tur...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[turner, did, not, withhold, his, disappointme...</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>i swear to god this dumb nigger bitch i have g...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[i, swear, to, god, this, dumb, nigger, bitch,...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>yea fuck you rt therealexel if youre a nigger ...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[yea, fuck, you, rt, therealexel, if, youre, a...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>bro u gotta chill rt chillshrammy dog fuck kp ...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[bro, u, got, ta, chill, rt, chillshrammy, dog...</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type  \\\n",
       "0      in other words katandandre your food was crapi...  not_cyberbullying   \n",
       "1      why is aussietv so white mkr theblock imaceleb...  not_cyberbullying   \n",
       "2      xochitlsuckkks a classy whore or more red velv...  not_cyberbullying   \n",
       "3      jasongio meh p  thanks for the heads up but no...  not_cyberbullying   \n",
       "4      rudhoeenglish this is an isis account pretendi...  not_cyberbullying   \n",
       "...                                                  ...                ...   \n",
       "47687  black ppl arent expected to do anything depend...          ethnicity   \n",
       "47688  turner did not withhold his disappointment tur...          ethnicity   \n",
       "47689  i swear to god this dumb nigger bitch i have g...          ethnicity   \n",
       "47690  yea fuck you rt therealexel if youre a nigger ...          ethnicity   \n",
       "47691  bro u gotta chill rt chillshrammy dog fuck kp ...          ethnicity   \n",
       "\n",
       "                                    tweet_text_tokenized  Token_Count  \\\n",
       "0      [in, other, words, katandandre, your, food, wa...            9   \n",
       "1      [why, is, aussietv, so, white, mkr, theblock, ...           13   \n",
       "2      [xochitlsuckkks, a, classy, whore, or, more, r...            9   \n",
       "3      [jasongio, meh, p, thanks, for, the, heads, up...           18   \n",
       "4      [rudhoeenglish, this, is, an, isis, account, p...           18   \n",
       "...                                                  ...          ...   \n",
       "47687  [black, ppl, arent, expected, to, do, anything...           42   \n",
       "47688  [turner, did, not, withhold, his, disappointme...           45   \n",
       "47689  [i, swear, to, god, this, dumb, nigger, bitch,...           20   \n",
       "47690  [yea, fuck, you, rt, therealexel, if, youre, a...           15   \n",
       "47691  [bro, u, got, ta, chill, rt, chillshrammy, dog...           15   \n",
       "\n",
       "       Word_Count  \n",
       "0               9  \n",
       "1              13  \n",
       "2               9  \n",
       "3              18  \n",
       "4              18  \n",
       "...           ...  \n",
       "47687          42  \n",
       "47688          45  \n",
       "47689          20  \n",
       "47690          15  \n",
       "47691          14  \n",
       "\n",
       "[47692 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba6b9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_no_Stop_Words'] = df['tweet_text_tokenized'].apply(remove_english_stopwords_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12fd8bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_stop_word_count'] = df['tweet_no_Stop_Words'].apply(word_count_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c596cc4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>tweet_text_tokenized</th>\n",
       "      <th>Token_Count</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>tweet_no_Stop_Words</th>\n",
       "      <th>tweet_stop_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words katandandre your food was crapi...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[in, other, words, katandandre, your, food, wa...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>words katandandre food crapilicious mkr</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is aussietv so white mkr theblock imaceleb...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[why, is, aussietv, so, white, mkr, theblock, ...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xochitlsuckkks a classy whore or more red velv...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[xochitlsuckkks, a, classy, whore, or, more, r...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>xochitlsuckkks classy whore red velvet cupcakes</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jasongio meh p  thanks for the heads up but no...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[jasongio, meh, p, thanks, for, the, heads, up...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>jasongio meh p thanks heads concerned another ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rudhoeenglish this is an isis account pretendi...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[rudhoeenglish, this, is, an, isis, account, p...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>rudhoeenglish isis account pretending kurdish ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>black ppl arent expected to do anything depend...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[black, ppl, arent, expected, to, do, anything...</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>black ppl arent expected anything depended any...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>turner did not withhold his disappointment tur...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[turner, did, not, withhold, his, disappointme...</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>turner withhold disappointment turner called c...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>i swear to god this dumb nigger bitch i have g...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[i, swear, to, god, this, dumb, nigger, bitch,...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>swear god dumb nigger bitch got bleach hair re...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>yea fuck you rt therealexel if youre a nigger ...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[yea, fuck, you, rt, therealexel, if, youre, a...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>yea fuck rt therealexel youre nigger fucking u...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>bro u gotta chill rt chillshrammy dog fuck kp ...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[bro, u, got, ta, chill, rt, chillshrammy, dog...</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>bro u got ta chill rt chillshrammy dog fuck kp...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type  \\\n",
       "0      in other words katandandre your food was crapi...  not_cyberbullying   \n",
       "1      why is aussietv so white mkr theblock imaceleb...  not_cyberbullying   \n",
       "2      xochitlsuckkks a classy whore or more red velv...  not_cyberbullying   \n",
       "3      jasongio meh p  thanks for the heads up but no...  not_cyberbullying   \n",
       "4      rudhoeenglish this is an isis account pretendi...  not_cyberbullying   \n",
       "...                                                  ...                ...   \n",
       "47687  black ppl arent expected to do anything depend...          ethnicity   \n",
       "47688  turner did not withhold his disappointment tur...          ethnicity   \n",
       "47689  i swear to god this dumb nigger bitch i have g...          ethnicity   \n",
       "47690  yea fuck you rt therealexel if youre a nigger ...          ethnicity   \n",
       "47691  bro u gotta chill rt chillshrammy dog fuck kp ...          ethnicity   \n",
       "\n",
       "                                    tweet_text_tokenized  Token_Count  \\\n",
       "0      [in, other, words, katandandre, your, food, wa...            9   \n",
       "1      [why, is, aussietv, so, white, mkr, theblock, ...           13   \n",
       "2      [xochitlsuckkks, a, classy, whore, or, more, r...            9   \n",
       "3      [jasongio, meh, p, thanks, for, the, heads, up...           18   \n",
       "4      [rudhoeenglish, this, is, an, isis, account, p...           18   \n",
       "...                                                  ...          ...   \n",
       "47687  [black, ppl, arent, expected, to, do, anything...           42   \n",
       "47688  [turner, did, not, withhold, his, disappointme...           45   \n",
       "47689  [i, swear, to, god, this, dumb, nigger, bitch,...           20   \n",
       "47690  [yea, fuck, you, rt, therealexel, if, youre, a...           15   \n",
       "47691  [bro, u, got, ta, chill, rt, chillshrammy, dog...           15   \n",
       "\n",
       "       Word_Count                                tweet_no_Stop_Words  \\\n",
       "0               9            words katandandre food crapilicious mkr   \n",
       "1              13  aussietv white mkr theblock imacelebrityau tod...   \n",
       "2               9    xochitlsuckkks classy whore red velvet cupcakes   \n",
       "3              18  jasongio meh p thanks heads concerned another ...   \n",
       "4              18  rudhoeenglish isis account pretending kurdish ...   \n",
       "...           ...                                                ...   \n",
       "47687          42  black ppl arent expected anything depended any...   \n",
       "47688          45  turner withhold disappointment turner called c...   \n",
       "47689          20  swear god dumb nigger bitch got bleach hair re...   \n",
       "47690          15  yea fuck rt therealexel youre nigger fucking u...   \n",
       "47691          14  bro u got ta chill rt chillshrammy dog fuck kp...   \n",
       "\n",
       "       tweet_stop_word_count  \n",
       "0                          5  \n",
       "1                         10  \n",
       "2                          6  \n",
       "3                         10  \n",
       "4                          9  \n",
       "...                      ...  \n",
       "47687                     22  \n",
       "47688                     29  \n",
       "47689                     13  \n",
       "47690                     11  \n",
       "47691                     14  \n",
       "\n",
       "[47692 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99e3a96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tweet_text</th>\n",
       "      <td>in other words katandandre your food was crapi...</td>\n",
       "      <td>why is aussietv so white mkr theblock imaceleb...</td>\n",
       "      <td>xochitlsuckkks a classy whore or more red velv...</td>\n",
       "      <td>jasongio meh p  thanks for the heads up but no...</td>\n",
       "      <td>rudhoeenglish this is an isis account pretendi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_text_tokenized</th>\n",
       "      <td>[in, other, words, katandandre, your, food, wa...</td>\n",
       "      <td>[why, is, aussietv, so, white, mkr, theblock, ...</td>\n",
       "      <td>[xochitlsuckkks, a, classy, whore, or, more, r...</td>\n",
       "      <td>[jasongio, meh, p, thanks, for, the, heads, up...</td>\n",
       "      <td>[rudhoeenglish, this, is, an, isis, account, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_Count</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word_Count</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_no_Stop_Words</th>\n",
       "      <td>words katandandre food crapilicious mkr</td>\n",
       "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
       "      <td>xochitlsuckkks classy whore red velvet cupcakes</td>\n",
       "      <td>jasongio meh p thanks heads concerned another ...</td>\n",
       "      <td>rudhoeenglish isis account pretending kurdish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_stop_word_count</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       0  \\\n",
       "tweet_text             in other words katandandre your food was crapi...   \n",
       "cyberbullying_type                                     not_cyberbullying   \n",
       "tweet_text_tokenized   [in, other, words, katandandre, your, food, wa...   \n",
       "Token_Count                                                            9   \n",
       "Word_Count                                                             9   \n",
       "tweet_no_Stop_Words              words katandandre food crapilicious mkr   \n",
       "tweet_stop_word_count                                                  5   \n",
       "\n",
       "                                                                       1  \\\n",
       "tweet_text             why is aussietv so white mkr theblock imaceleb...   \n",
       "cyberbullying_type                                     not_cyberbullying   \n",
       "tweet_text_tokenized   [why, is, aussietv, so, white, mkr, theblock, ...   \n",
       "Token_Count                                                           13   \n",
       "Word_Count                                                            13   \n",
       "tweet_no_Stop_Words    aussietv white mkr theblock imacelebrityau tod...   \n",
       "tweet_stop_word_count                                                 10   \n",
       "\n",
       "                                                                       2  \\\n",
       "tweet_text             xochitlsuckkks a classy whore or more red velv...   \n",
       "cyberbullying_type                                     not_cyberbullying   \n",
       "tweet_text_tokenized   [xochitlsuckkks, a, classy, whore, or, more, r...   \n",
       "Token_Count                                                            9   \n",
       "Word_Count                                                             9   \n",
       "tweet_no_Stop_Words      xochitlsuckkks classy whore red velvet cupcakes   \n",
       "tweet_stop_word_count                                                  6   \n",
       "\n",
       "                                                                       3  \\\n",
       "tweet_text             jasongio meh p  thanks for the heads up but no...   \n",
       "cyberbullying_type                                     not_cyberbullying   \n",
       "tweet_text_tokenized   [jasongio, meh, p, thanks, for, the, heads, up...   \n",
       "Token_Count                                                           18   \n",
       "Word_Count                                                            18   \n",
       "tweet_no_Stop_Words    jasongio meh p thanks heads concerned another ...   \n",
       "tweet_stop_word_count                                                 10   \n",
       "\n",
       "                                                                       4  \n",
       "tweet_text             rudhoeenglish this is an isis account pretendi...  \n",
       "cyberbullying_type                                     not_cyberbullying  \n",
       "tweet_text_tokenized   [rudhoeenglish, this, is, an, isis, account, p...  \n",
       "Token_Count                                                           18  \n",
       "Word_Count                                                            18  \n",
       "tweet_no_Stop_Words    rudhoeenglish isis account pretending kurdish ...  \n",
       "tweet_stop_word_count                                                  9  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410adc1",
   "metadata": {},
   "source": [
    "# Stemming, Normalizing, NER & POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99dcba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk import ne_chunk\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "edb5c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_stemming_func(text):\n",
    "    '''\n",
    "    Stemming tokens from string\n",
    "    \n",
    "    Step 1: Use word_tokenize() to get tokens from string\n",
    "    Step 2: Use PorterStemmer() to stem the created tokens\n",
    "    \n",
    "    Args:\n",
    "        text (str): String to which the functions are to be applied, string\n",
    "    \n",
    "    Returns:\n",
    "        String with stemmed words\n",
    "    '''  \n",
    "    words = word_tokenize(text)\n",
    "    text = ' '.join([PorterStemmer().stem(word) for word in words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "819986c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_lemm_v_a_func(text):\n",
    "    '''\n",
    "    Lemmatize tokens from string\n",
    "    \n",
    "    Step 1: Use word_tokenize() to get tokens from string\n",
    "    Step 2: Use WordNetLemmatizer() with POS tag 'v' to lemmatize the created tokens\n",
    "    Step 3: Use word_tokenize() to get tokens from generated string        \n",
    "    Step 4: Use WordNetLemmatizer() with POS tag 'a' to lemmatize the created tokens\n",
    "    \n",
    "    Args:\n",
    "        text (str): String to which the functions are to be applied, string\n",
    "    \n",
    "    Returns:\n",
    "        String with lemmatized words\n",
    "    '''\n",
    "    words1 = word_tokenize(text)\n",
    "    text1 = ' '.join([WordNetLemmatizer().lemmatize(word, pos='v') for word in words1])\n",
    "    words2 = word_tokenize(text1)\n",
    "    text2 = ' '.join([WordNetLemmatizer().lemmatize(word, pos='a') for word in words2])\n",
    "    return text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f14478b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets_lemmatized'] = df['tweet_no_Stop_Words'].apply(norm_lemm_v_a_func)\n",
    "\n",
    "df['Word_Count_lemmatized_tweet'] = df['tweets_lemmatized'].apply(word_count_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "04f4eb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>tweet_text_tokenized</th>\n",
       "      <th>Token_Count</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>tweet_no_Stop_Words</th>\n",
       "      <th>tweet_stop_word_count</th>\n",
       "      <th>tweets_lemmatized</th>\n",
       "      <th>Word_Count_lemmatized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words katandandre your food was crapi...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[in, other, words, katandandre, your, food, wa...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>words katandandre food crapilicious mkr</td>\n",
       "      <td>5</td>\n",
       "      <td>word katandandre food crapilicious mkr</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is aussietv so white mkr theblock imaceleb...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[why, is, aussietv, so, white, mkr, theblock, ...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
       "      <td>10</td>\n",
       "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xochitlsuckkks a classy whore or more red velv...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[xochitlsuckkks, a, classy, whore, or, more, r...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>xochitlsuckkks classy whore red velvet cupcakes</td>\n",
       "      <td>6</td>\n",
       "      <td>xochitlsuckkks classy whore red velvet cupcakes</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type  \\\n",
       "0  in other words katandandre your food was crapi...  not_cyberbullying   \n",
       "1  why is aussietv so white mkr theblock imaceleb...  not_cyberbullying   \n",
       "2  xochitlsuckkks a classy whore or more red velv...  not_cyberbullying   \n",
       "\n",
       "                                tweet_text_tokenized  Token_Count  Word_Count  \\\n",
       "0  [in, other, words, katandandre, your, food, wa...            9           9   \n",
       "1  [why, is, aussietv, so, white, mkr, theblock, ...           13          13   \n",
       "2  [xochitlsuckkks, a, classy, whore, or, more, r...            9           9   \n",
       "\n",
       "                                 tweet_no_Stop_Words  tweet_stop_word_count  \\\n",
       "0            words katandandre food crapilicious mkr                      5   \n",
       "1  aussietv white mkr theblock imacelebrityau tod...                     10   \n",
       "2    xochitlsuckkks classy whore red velvet cupcakes                      6   \n",
       "\n",
       "                                   tweets_lemmatized  \\\n",
       "0             word katandandre food crapilicious mkr   \n",
       "1  aussietv white mkr theblock imacelebrityau tod...   \n",
       "2    xochitlsuckkks classy whore red velvet cupcakes   \n",
       "\n",
       "   Word_Count_lemmatized_tweet  \n",
       "0                            5  \n",
       "1                           10  \n",
       "2                            6  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_stemming'] = df['tweet_no_Stop_Words'].apply(norm_stemming_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "67ed4ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tweet_text</th>\n",
       "      <td>in other words katandandre your food was crapi...</td>\n",
       "      <td>why is aussietv so white mkr theblock imaceleb...</td>\n",
       "      <td>xochitlsuckkks a classy whore or more red velv...</td>\n",
       "      <td>jasongio meh p  thanks for the heads up but no...</td>\n",
       "      <td>rudhoeenglish this is an isis account pretendi...</td>\n",
       "      <td>quickieleaks yes the test of god is that good...</td>\n",
       "      <td>itu sekolah ya bukan tempat bully ga jauh kaya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_text_tokenized</th>\n",
       "      <td>[in, other, words, katandandre, your, food, wa...</td>\n",
       "      <td>[why, is, aussietv, so, white, mkr, theblock, ...</td>\n",
       "      <td>[xochitlsuckkks, a, classy, whore, or, more, r...</td>\n",
       "      <td>[jasongio, meh, p, thanks, for, the, heads, up...</td>\n",
       "      <td>[rudhoeenglish, this, is, an, isis, account, p...</td>\n",
       "      <td>[quickieleaks, yes, the, test, of, god, is, th...</td>\n",
       "      <td>[itu, sekolah, ya, bukan, tempat, bully, ga, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_Count</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word_Count</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_no_Stop_Words</th>\n",
       "      <td>words katandandre food crapilicious mkr</td>\n",
       "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
       "      <td>xochitlsuckkks classy whore red velvet cupcakes</td>\n",
       "      <td>jasongio meh p thanks heads concerned another ...</td>\n",
       "      <td>rudhoeenglish isis account pretending kurdish ...</td>\n",
       "      <td>quickieleaks yes test god good bad indifferent...</td>\n",
       "      <td>itu sekolah ya bukan tempat bully ga jauh kaya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_stop_word_count</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweets_lemmatized</th>\n",
       "      <td>word katandandre food crapilicious mkr</td>\n",
       "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
       "      <td>xochitlsuckkks classy whore red velvet cupcakes</td>\n",
       "      <td>jasongio meh p thank head concern another angr...</td>\n",
       "      <td>rudhoeenglish isis account pretend kurdish acc...</td>\n",
       "      <td>quickieleaks yes test god good bad indifferent...</td>\n",
       "      <td>itu sekolah ya bukan tempat bully ga jauh kaya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word_Count_lemmatized_tweet</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             0  \\\n",
       "tweet_text                   in other words katandandre your food was crapi...   \n",
       "cyberbullying_type                                           not_cyberbullying   \n",
       "tweet_text_tokenized         [in, other, words, katandandre, your, food, wa...   \n",
       "Token_Count                                                                  9   \n",
       "Word_Count                                                                   9   \n",
       "tweet_no_Stop_Words                    words katandandre food crapilicious mkr   \n",
       "tweet_stop_word_count                                                        5   \n",
       "tweets_lemmatized                       word katandandre food crapilicious mkr   \n",
       "Word_Count_lemmatized_tweet                                                  5   \n",
       "\n",
       "                                                                             1  \\\n",
       "tweet_text                   why is aussietv so white mkr theblock imaceleb...   \n",
       "cyberbullying_type                                           not_cyberbullying   \n",
       "tweet_text_tokenized         [why, is, aussietv, so, white, mkr, theblock, ...   \n",
       "Token_Count                                                                 13   \n",
       "Word_Count                                                                  13   \n",
       "tweet_no_Stop_Words          aussietv white mkr theblock imacelebrityau tod...   \n",
       "tweet_stop_word_count                                                       10   \n",
       "tweets_lemmatized            aussietv white mkr theblock imacelebrityau tod...   \n",
       "Word_Count_lemmatized_tweet                                                 10   \n",
       "\n",
       "                                                                             2  \\\n",
       "tweet_text                   xochitlsuckkks a classy whore or more red velv...   \n",
       "cyberbullying_type                                           not_cyberbullying   \n",
       "tweet_text_tokenized         [xochitlsuckkks, a, classy, whore, or, more, r...   \n",
       "Token_Count                                                                  9   \n",
       "Word_Count                                                                   9   \n",
       "tweet_no_Stop_Words            xochitlsuckkks classy whore red velvet cupcakes   \n",
       "tweet_stop_word_count                                                        6   \n",
       "tweets_lemmatized              xochitlsuckkks classy whore red velvet cupcakes   \n",
       "Word_Count_lemmatized_tweet                                                  6   \n",
       "\n",
       "                                                                             3  \\\n",
       "tweet_text                   jasongio meh p  thanks for the heads up but no...   \n",
       "cyberbullying_type                                           not_cyberbullying   \n",
       "tweet_text_tokenized         [jasongio, meh, p, thanks, for, the, heads, up...   \n",
       "Token_Count                                                                 18   \n",
       "Word_Count                                                                  18   \n",
       "tweet_no_Stop_Words          jasongio meh p thanks heads concerned another ...   \n",
       "tweet_stop_word_count                                                       10   \n",
       "tweets_lemmatized            jasongio meh p thank head concern another angr...   \n",
       "Word_Count_lemmatized_tweet                                                 10   \n",
       "\n",
       "                                                                             4  \\\n",
       "tweet_text                   rudhoeenglish this is an isis account pretendi...   \n",
       "cyberbullying_type                                           not_cyberbullying   \n",
       "tweet_text_tokenized         [rudhoeenglish, this, is, an, isis, account, p...   \n",
       "Token_Count                                                                 18   \n",
       "Word_Count                                                                  18   \n",
       "tweet_no_Stop_Words          rudhoeenglish isis account pretending kurdish ...   \n",
       "tweet_stop_word_count                                                        9   \n",
       "tweets_lemmatized            rudhoeenglish isis account pretend kurdish acc...   \n",
       "Word_Count_lemmatized_tweet                                                  9   \n",
       "\n",
       "                                                                             5  \\\n",
       "tweet_text                    quickieleaks yes the test of god is that good...   \n",
       "cyberbullying_type                                           not_cyberbullying   \n",
       "tweet_text_tokenized         [quickieleaks, yes, the, test, of, god, is, th...   \n",
       "Token_Count                                                                 22   \n",
       "Word_Count                                                                  22   \n",
       "tweet_no_Stop_Words          quickieleaks yes test god good bad indifferent...   \n",
       "tweet_stop_word_count                                                       12   \n",
       "tweets_lemmatized            quickieleaks yes test god good bad indifferent...   \n",
       "Word_Count_lemmatized_tweet                                                 12   \n",
       "\n",
       "                                                                             6  \n",
       "tweet_text                   itu sekolah ya bukan tempat bully ga jauh kaya...  \n",
       "cyberbullying_type                                           not_cyberbullying  \n",
       "tweet_text_tokenized         [itu, sekolah, ya, bukan, tempat, bully, ga, j...  \n",
       "Token_Count                                                                 10  \n",
       "Word_Count                                                                  10  \n",
       "tweet_no_Stop_Words          itu sekolah ya bukan tempat bully ga jauh kaya...  \n",
       "tweet_stop_word_count                                                       10  \n",
       "tweets_lemmatized            itu sekolah ya bukan tempat bully ga jauh kaya...  \n",
       "Word_Count_lemmatized_tweet                                                 10  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(7).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b3599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
